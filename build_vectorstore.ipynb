{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "99211c50",
   "metadata": {},
   "source": [
    "# Build FAISS Vector Store for Product and Category Data using Hugging Face Embeddings\n",
    "\n",
    "This notebook loads exported categories and products data from PostgreSQL and creates a FAISS vector store for RAG queries. The vector store will enable semantic search over product information using lightweight embeddings from Hugging Face transformers optimized for Mac M1."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f65533d",
   "metadata": {},
   "source": [
    "## Import Required Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef0e398f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import necessary libraries\n",
    "import os\n",
    "import json\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "from typing import Dict, List, Any\n",
    "\n",
    "# LangChain components\n",
    "from langchain.embeddings import HuggingFaceEmbeddings\n",
    "from langchain.vectorstores import FAISS\n",
    "from langchain.schema import Document\n",
    "\n",
    "# Install required packages if needed\n",
    "# !pip install sentence-transformers huggingface-hub faiss-cpu langchain"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9212b598",
   "metadata": {},
   "source": [
    "## Initialize Hugging Face Embeddings\n",
    "\n",
    "We'll use a lightweight model that works well on Mac M1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43e86dfd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initialized embeddings using model: paraphrase-multilingual-MiniLM-L12-v2\n"
     ]
    }
   ],
   "source": [
    "# Initialize embeddings with a lightweight model optimized for Mac M1\n",
    "# Options include:\n",
    "# - 'all-MiniLM-L6-v2': Small (80MB) and fast, 384 dimensions\n",
    "# - 'paraphrase-multilingual-MiniLM-L12-v2': Good for multilingual (Vietnamese), 384 dimensions\n",
    "# - 'all-mpnet-base-v2': Better quality but larger (420MB), 768 dimensions\n",
    "\n",
    "# For best balance of size and quality for Vietnamese content\n",
    "model_name = \"paraphrase-multilingual-MiniLM-L12-v2\"\n",
    "\n",
    "# Initialize the Hugging Face embeddings\n",
    "embeddings = HuggingFaceEmbeddings(\n",
    "    model_name=model_name,\n",
    "    model_kwargs={'device': 'mps'},  # Use Metal Performance Shaders for M1 acceleration\n",
    "    encode_kwargs={'normalize_embeddings': True}  # Normalize for better similarity search\n",
    ")\n",
    "\n",
    "print(f\"Initialized embeddings using model: {model_name}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "838cac12",
   "metadata": {},
   "source": [
    "## Load Categories and Products Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07c038b1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Successfully loaded 182 categories from categories_202504171616.json\n",
      "Successfully loaded 3669 products from products_202504171616.json\n",
      "Successfully loaded 3669 products from products_202504171616.json\n"
     ]
    }
   ],
   "source": [
    "# File paths\n",
    "categories_file = \"categories_202504171616.json\"\n",
    "products_file = \"products_202504171616.json\"\n",
    "\n",
    "# Load categories data\n",
    "try:\n",
    "    with open(categories_file, \"r\", encoding=\"utf-8\") as f:\n",
    "        categories_data = json.load(f)\n",
    "        categories = categories_data.get('categories', [])\n",
    "        print(f\"Successfully loaded {len(categories)} categories from {categories_file}\")\n",
    "except Exception as e:\n",
    "    print(f\"Error loading categories file: {e}\")\n",
    "    categories = []\n",
    "\n",
    "# Load products data\n",
    "try:\n",
    "    with open(products_file, \"r\", encoding=\"utf-8\") as f:\n",
    "        products_data = json.load(f)\n",
    "        products = products_data.get('products', [])\n",
    "        print(f\"Successfully loaded {len(products)} products from {products_file}\")\n",
    "except Exception as e:\n",
    "    print(f\"Error loading products file: {e}\")\n",
    "    products = []"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "29490d2d",
   "metadata": {},
   "source": [
    "## Prepare Data for Vector Store\n",
    "\n",
    "We'll create Document objects from products and categories for embedding generation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "042c5893",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_product_document(product: Dict) -> Document:\n",
    "    \"\"\"Convert a product record to a Document for embedding\"\"\"\n",
    "\n",
    "    # Create a rich text representation of the product for embedding\n",
    "    product_text = f\"Product Name: {product.get('name', 'Unknown')}\\n\"\n",
    "    product_text += f\"Description: {product.get('description', 'No description')}\\n\"\n",
    "\n",
    "    # Add price information\n",
    "    price = product.get(\"price\")\n",
    "    currency = product.get(\"currency\", \"VND\")\n",
    "    if price:\n",
    "        product_text += f\"Price: {price} {currency}\\n\"\n",
    "\n",
    "    # Add specifications if available\n",
    "    specs = product.get(\"specifications\")\n",
    "    if specs and isinstance(specs, str):\n",
    "        try:\n",
    "            specs_dict = json.loads(specs)\n",
    "            product_text += \"Specifications:\\n\"\n",
    "            for key, value in specs_dict.items():\n",
    "                product_text += f\"- {key}: {value}\\n\"\n",
    "        except:\n",
    "            product_text += f\"Specifications: {specs}\\n\"\n",
    "\n",
    "    # Add tags if available\n",
    "    tags = product.get(\"tags\")\n",
    "    if tags:\n",
    "        product_text += f\"Tags: {tags}\\n\"\n",
    "\n",
    "    # Create metadata for the document\n",
    "    metadata = {\n",
    "        \"id\": product.get(\"id\"),\n",
    "        \"name\": product.get(\"name\"),\n",
    "        \"slug\": product.get(\"slug\"),\n",
    "        \"price\": product.get(\"price\"),\n",
    "        \"currency\": product.get(\"currency\"),\n",
    "        \"category_id\": product.get(\"category_id\"),\n",
    "        \"source\": \"product\",\n",
    "        \"rating\": product.get(\"rating\"),\n",
    "        \"is_active\": product.get(\"is_active\"),\n",
    "        \"stock_quantity\": product.get(\"stock_quantity\"),\n",
    "        \"featured_image\": product.get(\"images\", \"\").split(\",\")[0],\n",
    "    }\n",
    "\n",
    "    return Document(page_content=product_text, metadata=metadata)\n",
    "\n",
    "\n",
    "def create_category_document(category: Dict) -> Document:\n",
    "    \"\"\"Convert a category record to a Document for embedding\"\"\"\n",
    "\n",
    "    # Create a rich text representation of the category\n",
    "    category_text = f\"Category Name: {category.get('name', 'Unknown')}\\n\"\n",
    "    category_text += f\"Path: {category.get('path_url', 'No path')}\\n\"\n",
    "    category_text += f\"Products Count: {category.get('products_count', 0)}\\n\"\n",
    "\n",
    "    # Create metadata for the document\n",
    "    metadata = {\n",
    "        \"id\": category.get(\"id\"),\n",
    "        \"name\": category.get(\"name\"),\n",
    "        \"path_url\": category.get(\"path_url\"),\n",
    "        \"parent_id\": category.get(\"parent_id\"),\n",
    "        \"is_leaf\": category.get(\"is_leaf\"),\n",
    "        \"source\": \"category\",\n",
    "    }\n",
    "\n",
    "    return Document(page_content=category_text, metadata=metadata)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6cd65c7c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Converting products to documents...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 3669/3669 [00:00<00:00, 6271.33it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Created 3669 product documents\n",
      "\n",
      "Converting categories to documents...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 182/182 [00:00<00:00, 58276.46it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Created 182 category documents\n",
      "\n",
      "Total documents: 3851\n"
     ]
    }
   ],
   "source": [
    "# Convert products to documents\n",
    "print(\"Converting products to documents...\")\n",
    "product_documents = [create_product_document(product) for product in tqdm(products)]\n",
    "print(f\"Created {len(product_documents)} product documents\")\n",
    "\n",
    "# Convert categories to documents\n",
    "print(\"\\nConverting categories to documents...\")\n",
    "category_documents = [create_category_document(category) for category in tqdm(categories)]\n",
    "print(f\"Created {len(category_documents)} category documents\")\n",
    "\n",
    "# Combine all documents\n",
    "all_documents = product_documents + category_documents\n",
    "print(f\"\\nTotal documents: {len(all_documents)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "53b628b6",
   "metadata": {},
   "source": [
    "## Create and Save the FAISS Vector Store\n",
    "\n",
    "Using batch processing to be more memory-efficient for Mac M1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "046f97fc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating FAISS index with 3851 documents in batches of 50...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 78/78 [00:42<00:00,  1.85it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving FAISS index to ./faiss_index...\n",
      "FAISS index created and saved successfully!\n"
     ]
    }
   ],
   "source": [
    "# Directory to save the FAISS index\n",
    "faiss_index_path = \"./faiss_index\"\n",
    "\n",
    "# Define batch size for processing\n",
    "batch_size = 50  # Adjust based on your Mac M1's memory\n",
    "\n",
    "try:\n",
    "    print(f\"Creating FAISS index with {len(all_documents)} documents in batches of {batch_size}...\")\n",
    "    \n",
    "    # Process documents in batches to be more memory-efficient\n",
    "    vectorstore = None\n",
    "    for i in tqdm(range(0, len(all_documents), batch_size)):\n",
    "        # Get the current batch\n",
    "        batch = all_documents[i:i+batch_size]\n",
    "        \n",
    "        if vectorstore is None:\n",
    "            # Create a new vector store with the first batch\n",
    "            vectorstore = FAISS.from_documents(batch, embeddings)\n",
    "        else:\n",
    "            # Add subsequent batches to the existing vector store\n",
    "            batch_vectorstore = FAISS.from_documents(batch, embeddings)\n",
    "            vectorstore.merge_from(batch_vectorstore)\n",
    "        \n",
    "    # Save the vector store to disk\n",
    "    print(f\"Saving FAISS index to {faiss_index_path}...\")\n",
    "    vectorstore.save_local(faiss_index_path)\n",
    "    \n",
    "    print(\"FAISS index created and saved successfully!\")\n",
    "except Exception as e:\n",
    "    print(f\"Error creating FAISS index: {e}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a438054",
   "metadata": {},
   "source": [
    "## Save Refined Product Details\n",
    "\n",
    "Save the product details for future use in the agent."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "061b6443",
   "metadata": {},
   "source": [
    "## Test the Vector Store with Sample Queries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "df003035",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FAISS vector store loaded successfully!\n",
      "\n",
      "Search results for query: 'sản phẩm thủ công mỹ nghệ bằng gỗ'\n",
      "\n",
      "Result 1: Score = 0.6046595573425293\n",
      "Source: product\n",
      "Name: Hộp đựng đũa bằng gỗ MNV-SMTR-HD07\n",
      "Content: Product Name: Hộp đựng đũa bằng gỗ MNV-SMTR-HD07\n",
      "Description: Hộp đựng đũa bằng gỗ có độ bền cao theo thời gian, giúp bảo quản đũa ăn một cách vệ sinh và an toàn. Sản phẩm này ngăn chặn hiệu quả sự xâ...\n",
      "--------------------------------------------------------------------------------\n",
      "Result 2: Score = 0.6073907017707825\n",
      "Source: product\n",
      "Name: Đũa Đầu Nhựa 1p Mun MNV-MNTD08-1\n",
      "Content: Product Name: Đũa Đầu Nhựa 1p Mun MNV-MNTD08-1\n",
      "Description: Đũa gỗ sơn mài với màu sắc tinh tế và họa tiết trang nhã theo phong cách truyền thống Việt Nam. Sản phẩm được chế tác công phu bởi những ngư...\n",
      "--------------------------------------------------------------------------------\n",
      "Result 3: Score = 0.6092035174369812\n",
      "Source: product\n",
      "Name: Lịch gỗ note book MNV-QTN25-2\n",
      "Content: Product Name: Lịch gỗ note book MNV-QTN25-2\n",
      "Description: Kích thước: 17 x 10 cm\n",
      "Màu: Nâu\n",
      "Chất liệu: Gỗ\n",
      "Kiểu dáng: Hình chữ nhật\n",
      "\n",
      "\n",
      "Lịch gỗ để bàn\n",
      "\n",
      "\n",
      "Sản phẩm được làm bằng chất liệu gỗ thông, bề mặt mài...\n",
      "--------------------------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "# Function to load the vector store\n",
    "def load_vectorstore(index_path: str = faiss_index_path):\n",
    "    \"\"\"Load the FAISS vector store with Hugging Face embeddings\"\"\"\n",
    "    return FAISS.load_local(\n",
    "        index_path, embeddings, allow_dangerous_deserialization=True\n",
    "    )\n",
    "\n",
    "\n",
    "# Load the vector store\n",
    "try:\n",
    "    vectorstore = load_vectorstore()\n",
    "    print(\"FAISS vector store loaded successfully!\")\n",
    "\n",
    "    # Test with a sample query\n",
    "    query = \"sản phẩm thủ công mỹ nghệ bằng gỗ\"\n",
    "    results = vectorstore.similarity_search_with_score(query, k=3)\n",
    "\n",
    "    print(f\"\\nSearch results for query: '{query}'\\n\")\n",
    "    for i, (doc, score) in enumerate(results):\n",
    "        print(f\"Result {i + 1}: Score = {score}\")\n",
    "        print(f\"Source: {doc.metadata['source']}\")\n",
    "        print(f\"Name: {doc.metadata['name']}\")\n",
    "        print(f\"Content: {doc.page_content[:200]}...\")\n",
    "        print(\"-\" * 80)\n",
    "except Exception as e:\n",
    "    print(f\"Error testing vector store: {e}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c6b89677",
   "metadata": {},
   "source": [
    "## Performance Comparison\n",
    "\n",
    "Let's check the memory usage and speed of embeddings."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "b6ae931b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Memory usage before embeddings: 39.27 MB\n",
      "Memory usage after embeddings: 127.64 MB\n",
      "Time to embed 3 texts: 2.5931 seconds\n",
      "Embedding dimension: 384\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "import psutil\n",
    "\n",
    "def get_memory_usage():\n",
    "    \"\"\"Get current memory usage of the process in MB\"\"\"\n",
    "    process = psutil.Process(os.getpid())\n",
    "    mem_info = process.memory_info()\n",
    "    return mem_info.rss / 1024 / 1024  # Convert bytes to MB\n",
    "\n",
    "# Check embedding speed\n",
    "sample_texts = [\n",
    "    \"Sản phẩm thủ công mỹ nghệ bằng gỗ\",\n",
    "    \"Trang trí nội thất cao cấp\",\n",
    "    \"Đồ lưu niệm truyền thống Việt Nam\"\n",
    "]\n",
    "\n",
    "print(f\"Memory usage before embeddings: {get_memory_usage():.2f} MB\")\n",
    "\n",
    "start_time = time.time()\n",
    "embeddings_results = embeddings.embed_documents(sample_texts)\n",
    "end_time = time.time()\n",
    "\n",
    "print(f\"Memory usage after embeddings: {get_memory_usage():.2f} MB\")\n",
    "print(f\"Time to embed {len(sample_texts)} texts: {end_time - start_time:.4f} seconds\")\n",
    "print(f\"Embedding dimension: {len(embeddings_results[0])}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
