{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "9789fa8c",
   "metadata": {},
   "source": [
    "# HandcraftBK RAG Agent with LangChain\n",
    "\n",
    "This notebook creates an integrated RAG agent using LangChain that can:\n",
    "1. Query product data from the FAISS vector database using semantic search\n",
    "2. Make API calls to the products endpoint for filtering and sorting\n",
    "\n",
    "The agent uses LangChain's integration capabilities to provide a seamless experience between semantic search and structured API calls."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c8cf907",
   "metadata": {},
   "source": [
    "## Import Required Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe8d88c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "import requests\n",
    "from typing import Optional\n",
    "from pydantic import BaseModel, Field\n",
    "\n",
    "# LangChain components\n",
    "from langchain.embeddings import HuggingFaceEmbeddings\n",
    "from langchain.vectorstores import FAISS\n",
    "from langchain_core.prompts import ChatPromptTemplate, MessagesPlaceholder\n",
    "\n",
    "# LangChain tools and agent components\n",
    "from langchain.tools import tool\n",
    "\n",
    "# LangGraph components\n",
    "\n",
    "# LLM\n",
    "from langchain_together import ChatTogether\n",
    "\n",
    "# Python imports for API interactions\n",
    "import requests\n",
    "from urllib.parse import urlencode\n",
    "\n",
    "# Load environment variables\n",
    "import dotenv\n",
    "\n",
    "dotenv.load_dotenv()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c5f84a6e",
   "metadata": {},
   "source": [
    "## Configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17a746b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Configuration\n",
    "API_BASE_URL = \"http://localhost:3119/api\"\n",
    "VECTOR_STORE_PATH = \"./faiss_index\"\n",
    "TOGETHER_API_KEY = os.getenv(\"TOGETHER_API_KEY\")\n",
    "\n",
    "# Check if OpenAI API key is set\n",
    "if not TOGETHER_API_KEY:\n",
    "    print(\n",
    "        \"WARNING: TOGETHER_API_KEY not set. Set it using os.environ['TOGETHER_API_KEY'] = 'your-key'\"\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ca939d9",
   "metadata": {},
   "source": [
    "## Initialize Embeddings and Vector Store"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44673683",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize the HuggingFace embeddings (same model as used in build_vectorstore.ipynb)\n",
    "model_name = \"paraphrase-multilingual-MiniLM-L12-v2\"\n",
    "\n",
    "embeddings = HuggingFaceEmbeddings(\n",
    "    model_name=model_name,\n",
    "    model_kwargs={\"device\": \"mps\"},\n",
    "    encode_kwargs={\"normalize_embeddings\": True},\n",
    ")\n",
    "\n",
    "# Load the FAISS vector store\n",
    "try:\n",
    "    vectorstore = FAISS.load_local(\n",
    "        VECTOR_STORE_PATH, embeddings, allow_dangerous_deserialization=True\n",
    "    )\n",
    "    print(f\"Successfully loaded vector store from {VECTOR_STORE_PATH}\")\n",
    "except Exception as e:\n",
    "    print(f\"Error loading vector store: {e}\")\n",
    "    print(\n",
    "        \"Make sure you've run build_vectorstore.ipynb first to create the vector store.\"\n",
    "    )\n",
    "    vectorstore = None"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b951f5a4",
   "metadata": {},
   "source": [
    "## API Client Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bbd96dd1",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ProductsApiClient:\n",
    "    \"\"\"Client for interacting with the products API\"\"\"\n",
    "\n",
    "    def __init__(self, base_url):\n",
    "        self.base_url = base_url\n",
    "        self.session = requests.Session()\n",
    "\n",
    "    def get_products(self, **params):\n",
    "        \"\"\"Get products with optional filtering and sorting\"\"\"\n",
    "        # Remove None values\n",
    "        params = {k: v for k, v in params.items() if v is not None}\n",
    "        # Create query string\n",
    "        query_string = urlencode(params)\n",
    "        # Make the API request\n",
    "        url = f\"{self.base_url}/products?{query_string}\"\n",
    "\n",
    "        try:\n",
    "            response = self.session.get(url)\n",
    "            response.raise_for_status()\n",
    "            return response.json()\n",
    "        except requests.exceptions.RequestException as e:\n",
    "            return {\"error\": str(e)}\n",
    "\n",
    "    def get_product_by_slug(self, slug):\n",
    "        \"\"\"Get a specific product by its slug\"\"\"\n",
    "        url = f\"{self.base_url}/products/slug/{slug}\"\n",
    "\n",
    "        try:\n",
    "            response = self.session.get(url)\n",
    "            response.raise_for_status()\n",
    "            return response.json()\n",
    "        except requests.exceptions.RequestException as e:\n",
    "            return {\"error\": str(e)}\n",
    "\n",
    "\n",
    "class CategoriesApiClient:\n",
    "    \"\"\"Client for interacting with the categories API\"\"\"\n",
    "\n",
    "    def __init__(self, base_url):\n",
    "        self.base_url = base_url\n",
    "        self.session = requests.Session()\n",
    "\n",
    "    def get_menu_categories(self):\n",
    "        \"\"\"Get all categories for navigation menu\"\"\"\n",
    "        url = f\"{self.base_url}/categories/menu\"\n",
    "\n",
    "        try:\n",
    "            response = self.session.get(url)\n",
    "            response.raise_for_status()\n",
    "            return response.json()\n",
    "        except requests.exceptions.RequestException as e:\n",
    "            return {\"error\": str(e)}\n",
    "\n",
    "    def get_category_by_id(self, id, include_children=False, include_parents=False):\n",
    "        \"\"\"Get a specific category by its ID\"\"\"\n",
    "        params = {\n",
    "            \"includeChildren\": str(include_children).lower(),\n",
    "            \"includeParents\": str(include_parents).lower(),\n",
    "        }\n",
    "        query_string = urlencode(params)\n",
    "        url = f\"{self.base_url}/categories/{id}?{query_string}\"\n",
    "\n",
    "        try:\n",
    "            response = self.session.get(url)\n",
    "            response.raise_for_status()\n",
    "            return response.json()\n",
    "        except requests.exceptions.RequestException as e:\n",
    "            return {\"error\": str(e)}\n",
    "\n",
    "\n",
    "# Initialize the API clients\n",
    "api_client = ProductsApiClient(API_BASE_URL)\n",
    "categories_client = CategoriesApiClient(API_BASE_URL)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d500e70",
   "metadata": {},
   "source": [
    "## Define Custom Tools"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d62e5ed3",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ProductQueryParams(BaseModel):\n",
    "    \"\"\"Parameters for querying products API\"\"\"\n",
    "\n",
    "    page: Optional[int] = Field(default=1, description=\"Page number (starts from 1)\")\n",
    "    limit: Optional[int] = Field(\n",
    "        default=3, description=\"Number of items per page (max 100)\"\n",
    "    )\n",
    "    categoryId: Optional[str] = Field(default=None, description=\"Filter by category ID\")\n",
    "    minPrice: Optional[int] = Field(default=None, description=\"Filter by minimum price\")\n",
    "    maxPrice: Optional[int] = Field(default=None, description=\"Filter by maximum price\")\n",
    "    isActive: Optional[bool] = Field(\n",
    "        default=True, description=\"Filter by active status\"\n",
    "    )\n",
    "    inStock: Optional[bool] = Field(\n",
    "        default=True, description=\"Filter by stock availability\"\n",
    "    )\n",
    "    search: Optional[str] = Field(\n",
    "        default=None, description=\"Search in name, description, and tags\"\n",
    "    )\n",
    "    sortBy: Optional[str] = Field(\n",
    "        default=None,\n",
    "        description=\"Sort field (newest, price-asc, price-desc, popularity, top-seller)\",\n",
    "    )\n",
    "\n",
    "\n",
    "class CategoryQueryParams(BaseModel):\n",
    "    \"\"\"Parameters for querying a single category\"\"\"\n",
    "\n",
    "    id: str = Field(description=\"Category ID to retrieve\")\n",
    "    includeChildren: Optional[bool] = Field(\n",
    "        default=True, description=\"Include children categories\"\n",
    "    )\n",
    "    includeParents: Optional[bool] = Field(\n",
    "        default=True, description=\"Include parent categories\"\n",
    "    )\n",
    "\n",
    "\n",
    "@tool\n",
    "def get_menu_categories() -> str:\n",
    "    \"\"\"Get all main categories for the navigation menu.\n",
    "\n",
    "    Use this when the user asks about:\n",
    "    - Main/Available product categories\n",
    "\n",
    "    Returns:\n",
    "        A structured list of all available categories\n",
    "    \"\"\"\n",
    "    response = categories_client.get_menu_categories()\n",
    "\n",
    "    if \"error\" in response:\n",
    "        return json.dumps({\"error\": response[\"error\"]}, ensure_ascii=False)\n",
    "\n",
    "    # Format the categories in a readable way\n",
    "    if \"categories\" in response and len(response[\"categories\"]) > 0:\n",
    "        formatted_categories = []\n",
    "\n",
    "        for category in response[\"categories\"]:\n",
    "            cat_info = {\n",
    "                \"id\": category.get(\"id\"),\n",
    "                \"name\": category.get(\"name\"),\n",
    "                \"pathUrl\": category.get(\"pathUrl\"),\n",
    "                \"productsCount\": category.get(\"productsCount\", 0),\n",
    "                \"isLeaf\": category.get(\"isLeaf\", False),\n",
    "            }\n",
    "            formatted_categories.append(cat_info)\n",
    "\n",
    "        return json.dumps({\"categories\": formatted_categories}, ensure_ascii=False)\n",
    "    else:\n",
    "        return json.dumps({\"message\": \"No categories found\"}, ensure_ascii=False)\n",
    "\n",
    "\n",
    "@tool\n",
    "def get_category_by_id(params: CategoryQueryParams) -> str:\n",
    "    \"\"\"Get details about a specific category by its ID.\n",
    "\n",
    "    Use this when the user asks about:\n",
    "    - Details of a specific product category\n",
    "    - Products within a specific category\n",
    "\n",
    "    Args:\n",
    "        params: Parameters for retrieving category information\n",
    "\n",
    "    Returns:\n",
    "        Detailed information about the category, including parents and children if requested\n",
    "    \"\"\"\n",
    "    # Convert params to dictionary\n",
    "    params_dict = params.model_dump(exclude_none=True)\n",
    "    category_id = params_dict.pop(\"id\")\n",
    "\n",
    "    # Get category details from API\n",
    "    response = categories_client.get_category_by_id(category_id, **params_dict)\n",
    "\n",
    "    if \"error\" in response:\n",
    "        return json.dumps({\"error\": response[\"error\"]}, ensure_ascii=False)\n",
    "\n",
    "    # Format the category details in a readable way\n",
    "    formatted_category = {\n",
    "        \"id\": response.get(\"id\"),\n",
    "        \"name\": response.get(\"name\"),\n",
    "        \"pathUrl\": response.get(\"pathUrl\"),\n",
    "        \"productsCount\": response.get(\"productsCount\", 0),\n",
    "        \"isLeaf\": response.get(\"isLeaf\", False),\n",
    "    }\n",
    "\n",
    "    # Add parents if available\n",
    "    if \"parents\" in response and response[\"parents\"]:\n",
    "        formatted_category[\"parents\"] = [\n",
    "            {\n",
    "                \"id\": parent.get(\"id\"),\n",
    "                \"name\": parent.get(\"name\"),\n",
    "                \"pathUrl\": parent.get(\"pathUrl\"),\n",
    "            }\n",
    "            for parent in response[\"parents\"]\n",
    "        ]\n",
    "\n",
    "    # Add children if available\n",
    "    if \"children\" in response and response[\"children\"]:\n",
    "        formatted_category[\"children\"] = [\n",
    "            {\n",
    "                \"id\": child.get(\"id\"),\n",
    "                \"name\": child.get(\"name\"),\n",
    "                \"pathUrl\": child.get(\"pathUrl\"),\n",
    "                \"productsCount\": child.get(\"productsCount\", 0),\n",
    "            }\n",
    "            for child in response[\"children\"]\n",
    "        ]\n",
    "\n",
    "    return json.dumps(formatted_category, ensure_ascii=False)\n",
    "\n",
    "\n",
    "@tool\n",
    "def query_products_api(params: ProductQueryParams) -> str:\n",
    "    \"\"\"Query the products API with filtering and sorting options.\n",
    "\n",
    "    Use this when the user wants to:\n",
    "    - Find products in specific price ranges\n",
    "    - Sort products by newest, price-asc (Price from low to high), price-desc (Price from high to low), popularity, top-seller.\n",
    "    - Check products that are in stock\n",
    "    - Limit the number of products returned to 3 per query.\n",
    "\n",
    "    Examples:\n",
    "    - What are your most popular products?\n",
    "    - Do you have any wooden bowls in stock?\n",
    "    - Sort products by price from low to high\n",
    "\n",
    "    Args:\n",
    "        params: Parameters for filtering and sorting products\n",
    "\n",
    "    Returns:\n",
    "        JSON response from the API as a string\n",
    "    \"\"\"\n",
    "    # Convert params to dictionary\n",
    "    params_dict = params.model_dump(exclude_none=True)\n",
    "\n",
    "    # Get products from API\n",
    "    response = api_client.get_products(**params_dict)\n",
    "    print(\"API Response:\", response)\n",
    "    # Format the results in a more readable way\n",
    "    if \"items\" in response and len(response[\"items\"]) > 0:\n",
    "        products_info = []\n",
    "        for product in response[\"items\"]:\n",
    "            info = {\n",
    "                \"id\": product.get(\"id\"),\n",
    "                \"name\": product.get(\"name\"),\n",
    "                \"price\": product.get(\"price\", 0),\n",
    "                \"currency\": product.get(\"currency\", \"VND\"),\n",
    "                \"rating\": product.get(\"rating\"),\n",
    "                \"inStock\": product.get(\"stockQuantity\", 0) > 0,\n",
    "                \"description\": product.get(\"description\", \"\")[:100]\n",
    "                + (\"...\" if len(product.get(\"description\", \"\")) > 100 else \"\"),\n",
    "                \"featured_image\": product.get(\"images\")[0]\n",
    "                if product.get(\"images\") and len(product.get(\"images\")) > 0\n",
    "                else None,\n",
    "                \"slug\": product.get(\"slug\"),\n",
    "                \"stockQuantity\": product.get(\"stockQuantity\"),\n",
    "                \"category\": product.get(\"category\").get(\"name\"),\n",
    "            }\n",
    "            products_info.append(info)\n",
    "\n",
    "        result = {\n",
    "            \"products\": products_info,\n",
    "        }\n",
    "        return json.dumps(result, ensure_ascii=False)\n",
    "    else:\n",
    "        return json.dumps(\n",
    "            {\"message\": \"No products found matching the criteria\"}, ensure_ascii=False\n",
    "        )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec843c47",
   "metadata": {},
   "source": [
    "## Setup Vector Store Retriever"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bef397fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create retriever from the vector store\n",
    "if vectorstore is not None:\n",
    "    retriever = vectorstore.as_retriever(\n",
    "        search_type=\"similarity\", search_kwargs={\"k\": 3}\n",
    "    )\n",
    "else:\n",
    "    print(\"Warning: Vector store is not available, retriever will not work\")\n",
    "    retriever = None\n",
    "\n",
    "\n",
    "# Define a tool that uses the retriever\n",
    "@tool\n",
    "def semantic_search(query: str) -> str:\n",
    "    \"\"\"Search for products or categories semantically using the vector database.\n",
    "\n",
    "    Use this tool for natural language queries about products when:\n",
    "    - The user asks about product features or characteristics\n",
    "    - The user wants recommendations based on specific needs\n",
    "    - The user asks general questions about product types or categories\n",
    "    - If category name is not available, request to get_category_by_id to get category name.\n",
    "    - You need detailed product information that might not be captured by API filters\n",
    "\n",
    "    Example queries:\n",
    "    - Which products would be good as gifts?\n",
    "    - What are the characteristics of bamboo products?\n",
    "    - Can you recommend products that represent Vietnamese culture?\n",
    "\n",
    "    Args:\n",
    "        query: The natural language search query\n",
    "\n",
    "    Returns:\n",
    "        Relevant product or category information based on the query\n",
    "    \"\"\"\n",
    "    if retriever is None:\n",
    "        return \"Vector store is not available.\"\n",
    "\n",
    "    docs = retriever.invoke(query)\n",
    "\n",
    "    results = []\n",
    "    for i, doc in enumerate(docs):\n",
    "        source_type = doc.metadata.get(\"source\", \"unknown\")\n",
    "\n",
    "        if source_type == \"product\":\n",
    "            result = f\"Product {i + 1}:\\n\"\n",
    "        elif source_type == \"category\":\n",
    "            result = f\"Category {i + 1}:\\n\"\n",
    "        result += doc.page_content\n",
    "        result += json.dumps(doc.metadata, ensure_ascii=False)\n",
    "\n",
    "        results.append(result)\n",
    "\n",
    "    return \"\\n\\n\".join(results)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b1ce6b26",
   "metadata": {},
   "source": [
    "## Initialize LLM and Create LangChain Agent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e628859",
   "metadata": {},
   "outputs": [],
   "source": [
    "llm = ChatTogether(\n",
    "    temperature=0,\n",
    "    model=\"meta-llama/Llama-3.3-70B-Instruct-Turbo-Free\",\n",
    "    api_key=TOGETHER_API_KEY,\n",
    ")\n",
    "\n",
    "tools = [\n",
    "    query_products_api,\n",
    "    semantic_search,\n",
    "    get_menu_categories,\n",
    "    get_category_by_id,\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac128141",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.messages import ToolMessage\n",
    "from langchain_core.runnables import RunnableLambda\n",
    "\n",
    "from langgraph.prebuilt import ToolNode\n",
    "\n",
    "\n",
    "def handle_tool_error(state) -> dict:\n",
    "    error = state.get(\"error\")\n",
    "    tool_calls = state[\"messages\"][-1].tool_calls\n",
    "    return {\n",
    "        \"messages\": [\n",
    "            ToolMessage(\n",
    "                content=f\"Error: {repr(error)}\\n please fix your mistakes.\",\n",
    "                tool_call_id=tc[\"id\"],\n",
    "            )\n",
    "            for tc in tool_calls\n",
    "        ]\n",
    "    }\n",
    "\n",
    "\n",
    "def create_tool_node_with_fallback(tools: list) -> dict:\n",
    "    return ToolNode(tools).with_fallbacks(\n",
    "        [RunnableLambda(handle_tool_error)], exception_key=\"error\"\n",
    "    )\n",
    "\n",
    "\n",
    "def _print_event(event: dict, _printed: set, max_length=1500):\n",
    "    current_state = event.get(\"dialog_state\")\n",
    "    if current_state:\n",
    "        print(\"Currently in: \", current_state[-1])\n",
    "    message = event.get(\"messages\")\n",
    "    if message:\n",
    "        if isinstance(message, list):\n",
    "            message = message[-1]\n",
    "        if message.id not in _printed:\n",
    "            msg_repr = message.pretty_repr(html=True)\n",
    "            if len(msg_repr) > max_length:\n",
    "                msg_repr = msg_repr[:max_length] + \" ...\"\n",
    "            print(msg_repr)\n",
    "            _printed.add(message.id)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7596f2d6",
   "metadata": {},
   "source": [
    "## Define Agent Prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cacf8baf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create agent prompt\n",
    "prompt = ChatPromptTemplate.from_messages(\n",
    "    [\n",
    "        (\n",
    "            \"system\",\n",
    "            \"\"\"You are a helpful shopping assistant for HandcraftBK, a Vietnamese artisanal handicraft store.\n",
    "You help customers find and learn about Vietnamese handicraft products and categories.\n",
    "Instruction for the tool to assist customers has been provided.\n",
    "\n",
    "When providing category information, format it in markdown style with the following details in order:\n",
    "1. ### [Category Name]\n",
    "2. **Products Count:** [Number of products in this category]\n",
    "3. Include category path url [Category path URL] in pattern (/categories/[category-slug])\n",
    "\n",
    "Example category information format:\n",
    "```\n",
    "### Handcrafted Wooden Bowls\n",
    "**Products Count:** 25\n",
    "[Category Url] /categories/handcrafted-wooden-bowls-c2323\n",
    "```\n",
    "\n",
    "When providing product information by using semantic_search:\n",
    "- Description: A summary of the product description about 40-60 words base on [Description] in result\n",
    "- Use get_category_by_id to get category name from categoryId.\n",
    "\n",
    "When providing product information, format it in markdown style with the following details in order:\n",
    "1. ### [Product Name]\n",
    "2. **Price:** [Price formatted with comma separators] VND (if price is 0, use \"Contact us\"/\"Liên hệ\")\n",
    "3. **Description:** A concise summary of the product description about 40-60 words\n",
    "4. **Category:** [Category Name]\n",
    "5. **Rating:** [Rating]/5 ([Review Count] reviews)\n",
    "6. **Stock:** [In stock/Out of stock] ([Stock Quantity] available)\n",
    "7. Include product path url (/products/[product-slug])\n",
    "8. Include a feature image link [featured_image]\n",
    "\n",
    "Example product information format:\n",
    "```\n",
    "### Handcrafted Wooden Bowl\n",
    "**Price:** 299,000 VND\n",
    "**Description:** Beautiful handcrafted wooden bowl made from sustainable oak wood...\n",
    "**Category:** Kitchenware\n",
    "**Rating:** 4.5/5 (42 reviews)\n",
    "**Stock:** In stock (25 available)\n",
    "[View Product](/products/handcrafted-wooden-bowl-p3434)\n",
    "![Product Image](https://example.com/images/bowl1.jpg)\n",
    "```\n",
    "\n",
    "Always respond in a helpful and friendly manner. Format prices in Vietnamese Dong (VND) with comma separators (e.g., 1,460,000 VND).\n",
    "Please answer only in English/Vietnamese.\n",
    "If you do not know the answer, respond with \"I don't know\" or \"Xin lỗi, tôi không biết.\"\n",
    "NEVER make stuff up if you don't have enough information to answer... just say you don't have enough information.\n",
    "\"\"\",\n",
    "        ),\n",
    "        MessagesPlaceholder(variable_name=\"messages\"),\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a216018",
   "metadata": {},
   "source": [
    "## Create the LangGraph Agent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc85dfe4",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.runnables import Runnable, RunnableConfig\n",
    "from typing import Annotated\n",
    "from typing_extensions import TypedDict\n",
    "from langgraph.graph.message import AnyMessage, add_messages\n",
    "\n",
    "\n",
    "class State(TypedDict):\n",
    "    messages: Annotated[list[AnyMessage], add_messages]\n",
    "\n",
    "\n",
    "class Assistant:\n",
    "    def __init__(self, runnable: Runnable):\n",
    "        self.runnable = runnable\n",
    "\n",
    "    def __call__(self, state: State, config: RunnableConfig):\n",
    "        while True:\n",
    "            # Invoke the runnable with the original state (containing 'messages')\n",
    "            result = self.runnable.invoke(state)\n",
    "            # If the LLM happens to return an empty response, we will re-prompt it\n",
    "            # for an actual response.\n",
    "            if not result.tool_calls and (\n",
    "                not result.content\n",
    "                or isinstance(result.content, list)\n",
    "                and not result.content[0].get(\"text\")\n",
    "            ):\n",
    "                messages = state[\"messages\"] + [(\"user\", \"Respond with a real output.\")]\n",
    "                state = {**state, \"messages\": messages}\n",
    "            else:\n",
    "                break\n",
    "        return {\"messages\": result}\n",
    "\n",
    "\n",
    "assistant_runnable = prompt | llm.bind_tools(tools)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b5c1b797",
   "metadata": {},
   "source": [
    "## Define graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c931ccb1",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langgraph.checkpoint.memory import MemorySaver\n",
    "from langgraph.graph import StateGraph, START\n",
    "from langgraph.prebuilt import tools_condition\n",
    "\n",
    "builder = StateGraph(State)\n",
    "\n",
    "\n",
    "# Define nodes: these do the work\n",
    "builder.add_node(\"assistant\", Assistant(assistant_runnable))\n",
    "builder.add_node(\"tools\", create_tool_node_with_fallback(tools))\n",
    "# Define edges: these determine how the control flow moves\n",
    "builder.add_edge(START, \"assistant\")\n",
    "builder.add_conditional_edges(\n",
    "    \"assistant\",\n",
    "    tools_condition,\n",
    ")\n",
    "builder.add_edge(\"tools\", \"assistant\")\n",
    "\n",
    "# The checkpointer lets the graph persist its state\n",
    "# this is a complete memory for the entire graph.\n",
    "memory = MemorySaver()\n",
    "graph = builder.compile(checkpointer=memory)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42d6d764",
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import Image, display\n",
    "\n",
    "try:\n",
    "    display(Image(graph.get_graph().draw_mermaid_png()))\n",
    "except Exception:\n",
    "    # This requires some extra dependencies and is optional\n",
    "    pass"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae0b03cf",
   "metadata": {},
   "source": [
    "## Agent Interface\n",
    "\n",
    "Run this cell to interact with the agent."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53e31ad4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import uuid\n",
    "\n",
    "# config = {\"configurable\": {\"thread_id\": str(uuid.uuid4())}}\n",
    "\n",
    "# # Example usage\n",
    "# query = \"Which products would be good as gifts?\"\n",
    "# _printed = set()\n",
    "# events = graph.stream({\"messages\": (\"user\", query)}, config, stream_mode=\"values\")\n",
    "# for event in events:\n",
    "#     _print_event(event, _printed)\n",
    "# # print(f\"Query: {query}\")\n",
    "# # print(f\"Response: {response}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "963b8bdf",
   "metadata": {},
   "source": [
    "## Example Queries\n",
    "\n",
    "Here are some example queries you can try with the agent:\n",
    "\n",
    "### API-based Queries (uses query_products_api):\n",
    "- Show me products under 500,000 VND\n",
    "- What are your most popular products?\n",
    "- Do you have any wooden bowls in stock?\n",
    "- Sort products by price from low to high\n",
    "- Show me products in the home decor category\n",
    "\n",
    "### Semantic Search Queries (uses semantic_search):\n",
    "- What materials are used in your lacquer products?\n",
    "- Tell me about traditional Vietnamese handicraft techniques\n",
    "- Which products would be good as gifts?\n",
    "- What are the characteristics of bamboo products?\n",
    "- Can you recommend products that represent Vietnamese culture?\n",
    "\n",
    "### Specific Product Queries (uses get_product_by_slug or semantic_search):\n",
    "- Tell me about the Handcrafted Wooden Bowl\n",
    "- What are the dimensions of the lacquer painting?\n",
    "- Is the bamboo basket handmade?\n",
    "\n",
    "### Category Queries (uses get_menu_categories or get_category_by_id):\n",
    "- What categories of products do you have?\n",
    "- Tell me about the home decor category\n",
    "- What subcategories are under the kitchenware category?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de106674",
   "metadata": {},
   "source": [
    "## FastAPI API for Single-Turn Chatbot Interaction\n",
    "\n",
    "This cell creates a FastAPI API endpoint `/chat` that accepts a user message and returns a single-turn response from the chatbot agent. To run the API server, uncomment the last line."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "446cb4f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# FastAPI single-turn chatbot API\n",
    "from fastapi import FastAPI, Request\n",
    "from fastapi.responses import JSONResponse\n",
    "import uvicorn\n",
    "import uuid\n",
    "\n",
    "app = FastAPI()\n",
    "\n",
    "@app.post(\"/chat\")\n",
    "async def chat_endpoint(request: Request):\n",
    "    data = await request.json()\n",
    "    user_message = data.get(\"message\")\n",
    "    if not user_message:\n",
    "        return JSONResponse({\"error\": \"Missing 'message' in request body.\"}, status_code=400)\n",
    "\n",
    "    config = {\"configurable\": {\"thread_id\": str(uuid.uuid4())}}\n",
    "    # Use invoke instead of stream for single-turn\n",
    "    result = graph.invoke({\"messages\": (\"user\", user_message)}, config)\n",
    "    response_text = None\n",
    "    messages = result.get(\"messages\")\n",
    "    if messages:\n",
    "        if isinstance(messages, list):\n",
    "            last_message = messages[-1]\n",
    "        else:\n",
    "            last_message = messages\n",
    "        if hasattr(last_message, 'content'):\n",
    "            response_text = last_message.content\n",
    "    if response_text is None:\n",
    "        response_text = \"No response from chatbot.\"\n",
    "    return {\"response\": response_text}\n",
    "\n",
    "# To run the API server, uncomment the following line and run this cell:\n",
    "# uvicorn.run(app, host=\"0.0.0.0\", port=8000)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
